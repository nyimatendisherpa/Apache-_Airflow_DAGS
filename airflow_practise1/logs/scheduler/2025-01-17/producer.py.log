[2025-01-17T05:25:25.312+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:25:25.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:25:25.556+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:25:25.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:25:47.286+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:34:16.481+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.421+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:producer
[2025-01-17T05:34:16.678+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.677+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:producer
[2025-01-17T05:34:16.748+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.746+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:producer
[2025-01-17T05:34:16.814+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.805+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:producer
[2025-01-17T05:34:16.870+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.869+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:producer
[2025-01-17T05:34:16.922+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.919+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:producer
[2025-01-17T05:34:16.989+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.988+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:producer
[2025-01-17T05:34:16.997+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:16.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T05:34:17.197+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:17.196+0000] {dag.py:3262} INFO - Creating ORM DAG for producer
[2025-01-17T05:34:17.514+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:17.509+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T05:34:17.796+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 193, in _handle_dag_file_processing
    result_channel.send(result)
  File "/usr/local/lib/python3.12/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/usr/local/lib/python3.12/multiprocessing/connection.py", line 427, in _send_bytes
    self._send(header + buf)
  File "/usr/local/lib/python3.12/multiprocessing/connection.py", line 384, in _send
    n = write(self._handle, buf)
        ^^^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
[2025-01-17T05:34:56.714+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:34:56.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:34:57.023+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:34:56.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:34:58.832+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:35:02.403+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:35:02.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T05:35:05.017+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:35:05.003+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T05:35:06.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 10.398 seconds
[2025-01-17T05:35:42.250+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:35:42.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:35:42.267+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:35:42.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:35:42.365+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:35:42.558+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:35:42.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T05:35:42.899+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:35:42.897+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T05:35:43.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 0.890 seconds
[2025-01-17T05:36:15.114+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:36:15.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:36:15.155+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:36:15.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:36:15.250+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:36:15.433+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:36:15.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T05:36:15.543+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:36:15.541+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T05:36:15.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 0.561 seconds
[2025-01-17T05:38:44.363+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:38:44.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:38:45.311+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:38:45.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:38:51.417+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:40:54.099+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-17T05:44:34.456+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:44:34.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:44:34.785+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:44:34.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:44:37.155+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T05:55:38.756+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/producer.py
[2025-01-17T05:55:38.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T05:55:40.239+0000] {logging_mixin.py:190} INFO - [2025-01-17T05:55:40.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T05:56:06.206+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:02:43.732+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:02:43.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:02:44.436+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:02:44.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:03:12.859+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:20:36.521+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:20:36.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:20:36.796+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:20:36.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:20:37.507+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:20:39.269+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:20:39.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T06:20:39.615+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:20:39.614+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T06:20:40.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 4.080 seconds
[2025-01-17T06:21:11.226+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:21:11.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:21:11.235+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:21:11.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:21:11.268+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:21:11.325+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:21:11.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T06:21:11.383+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:21:11.382+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T06:21:11.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 0.229 seconds
[2025-01-17T06:26:24.790+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:26:24.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:26:24.936+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:26:24.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:26:27.526+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:36:06.703+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:36:06.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:36:07.173+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:36:06.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:36:15.613+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:43:33.477+0000] {processor.py:186} INFO - Started process (PID=481) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:43:33.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:43:33.663+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:43:33.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:43:44.267+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:52:09.459+0000] {processor.py:186} INFO - Started process (PID=518) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:52:09.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:52:09.694+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:52:09.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:52:14.902+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:57:40.778+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:57:40.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:57:41.030+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:57:41.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:57:41.577+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:57:42.800+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:57:42.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T06:57:43.212+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:57:43.208+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T06:57:43.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 3.131 seconds
[2025-01-17T06:58:14.181+0000] {processor.py:186} INFO - Started process (PID=556) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:58:14.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:58:14.192+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:58:14.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:58:14.242+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:58:14.324+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:58:14.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T06:58:14.398+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:58:14.398+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T06:58:14.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 0.309 seconds
[2025-01-17T06:59:40.254+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/producer.py
[2025-01-17T06:59:40.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T06:59:40.634+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:59:40.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T06:59:42.157+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T06:59:55.810+0000] {logging_mixin.py:190} INFO - [2025-01-17T06:59:54.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T07:01:05.614+0000] {logging_mixin.py:190} INFO - [2025-01-17T07:01:03.833+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T07:07:58.636+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/producer.py
[2025-01-17T07:07:58.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/producer.py for tasks to queue
[2025-01-17T07:07:58.660+0000] {logging_mixin.py:190} INFO - [2025-01-17T07:07:58.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/producer.py
[2025-01-17T07:07:59.053+0000] {processor.py:925} INFO - DAG(s) 'producer' retrieved from /opt/airflow/dags/producer.py
[2025-01-17T07:08:00.049+0000] {logging_mixin.py:190} INFO - [2025-01-17T07:08:00.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-17T07:08:00.238+0000] {logging_mixin.py:190} INFO - [2025-01-17T07:08:00.231+0000] {dag.py:4180} INFO - Setting next_dagrun for producer to 2025-01-16 00:00:00+00:00, run_after=2025-01-17 00:00:00+00:00
[2025-01-17T07:08:00.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/producer.py took 1.987 seconds
